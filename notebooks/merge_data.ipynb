{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2913015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "# Directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e0fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Configuration ---\n",
    "# IMPORTANT: This path MUST match the DATA_FOLDER used in your scraping script.\n",
    "# It should point to the directory where your individual channel CSV files are saved.\n",
    "DATA_FOLDER = r'D:\\kaimtenx\\project\\week4\\Amharic-Ecommerce-Data-Extractor\\data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "004941db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data merging process from: D:\\kaimtenx\\project\\week4\\Amharic-Ecommerce-Data-Extractor\\data\n",
      "Loaded 'Fashiontera_data.csv' (1975 rows)\n",
      "Loaded 'meneshayeofficial_data.csv' (876 rows)\n",
      "Loaded 'shageronlinestore_data.csv' (4061 rows)\n",
      "Loaded 'Shewabrand_data.csv' (2702 rows)\n",
      "Loaded 'ZemenExpress_data.csv' (4839 rows)\n",
      "\n",
      "--- Concatenating all loaded dataframes ---\n",
      "Initial merged dataframe size: 14453 rows\n",
      "Applying basic post-merge preprocessing...\n",
      "Converted 'date' column to datetime.\n",
      "Basic tokenization applied to 'message' column, creating 'tokens'.\n",
      "\n",
      "Successfully merged all data and saved to 'D:\\kaimtenx\\project\\week4\\Amharic-Ecommerce-Data-Extractor\\data\\cleaned_data.csv'\n",
      "Total rows in final merged file: 14453\n"
     ]
    }
   ],
   "source": [
    "# --- Main Merging Logic ---\n",
    "\n",
    "def merge_scraped_data(data_folder):\n",
    "    \"\"\"\n",
    "    Merges all individual CSV files (assumed to be from channel scrapes)\n",
    "    in the specified folder into a single cleaned_data.csv file.\n",
    "    \"\"\"\n",
    "    print(f\"Starting data merging process from: {data_folder}\")\n",
    "    \n",
    "    if not os.path.isdir(data_folder):\n",
    "        print(f\"Error: Data folder '{data_folder}' does not exist. Please ensure your scraping script ran successfully.\")\n",
    "        return\n",
    "\n",
    "    all_scraped_dataframes = []\n",
    "    \n",
    "    # List all files in the data folder\n",
    "    for filename in os.listdir(data_folder):\n",
    "        # Check if it's a CSV file and likely an individual channel data file\n",
    "        if filename.endswith('_data.csv'):\n",
    "            file_path = os.path.join(data_folder, filename)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding='utf-8')\n",
    "                all_scraped_dataframes.append(df)\n",
    "                print(f\"Loaded '{filename}' ({len(df)} rows)\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load '{filename}'. Error: {e}\")\n",
    "\n",
    "    if all_scraped_dataframes:\n",
    "        print(\"\\n--- Concatenating all loaded dataframes ---\")\n",
    "        merged_df = pd.concat(all_scraped_dataframes, ignore_index=True)\n",
    "        print(f\"Initial merged dataframe size: {len(merged_df)} rows\")\n",
    "\n",
    "        # --- Apply Basic Preprocessing (similar to original script) ---\n",
    "        print(\"Applying basic post-merge preprocessing...\")\n",
    "\n",
    "        # Convert 'date' column to datetime objects\n",
    "        # Use errors='coerce' to turn unparseable dates into NaT (Not a Time)\n",
    "        merged_df['date'] = pd.to_datetime(merged_df['date'], errors='coerce')\n",
    "        print(\"Converted 'date' column to datetime.\")\n",
    "\n",
    "        # Drop 'sender_id' if it's mostly empty (assuming it's consistently empty or not useful)\n",
    "        # Check if column exists and if all its values are null\n",
    "        if 'sender_id' in merged_df.columns and merged_df['sender_id'].isnull().all():\n",
    "            merged_df = merged_df.drop(columns=['sender_id'])\n",
    "            print(\"Dropped 'sender_id' column as it was entirely empty in all merged data.\")\n",
    "        elif 'sender_id' in merged_df.columns and merged_df['sender_id'].isnull().sum() > 0:\n",
    "             print(f\"Note: 'sender_id' column has {merged_df['sender_id'].isnull().sum()} missing values but not all. Keeping column.\")\n",
    "\n",
    "\n",
    "        # Basic tokenization for the 'message' column\n",
    "        # This is a simple split-and-strip; for robust Amharic NLP, consider specialized libraries\n",
    "        merged_df['tokens'] = merged_df['message'].apply(\n",
    "            lambda x: [word.strip() for word in str(x).replace('\\n', ' ').split() if word.strip()]\n",
    "            if pd.notna(x) else []\n",
    "        )\n",
    "        print(\"Basic tokenization applied to 'message' column, creating 'tokens'.\")\n",
    "        \n",
    "        # Ensure 'channel' is string type (if it somehow became numeric from IDs)\n",
    "        merged_df['channel'] = merged_df['channel'].astype(str)\n",
    "\n",
    "        # Define the output path for the merged file\n",
    "        merged_file_path = os.path.join(data_folder, 'cleaned_data.csv')\n",
    "        merged_df.to_csv(merged_file_path, index=False, encoding='utf-8')\n",
    "        print(f\"\\nSuccessfully merged all data and saved to '{merged_file_path}'\")\n",
    "        print(f\"Total rows in final merged file: {len(merged_df)}\")\n",
    "    else:\n",
    "        print(\"\\nNo individual channel CSV files were found to merge. Please run the scraping script first.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    merge_scraped_data(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10bcfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cleaned data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
